<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>David Fan</title>
    <link>https://davidfan.io/</link>
    <description>Recent content on David Fan</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 27 Feb 2022 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://davidfan.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Breaking into Industry ML/AI Research Without a PhD</title>
      <link>https://davidfan.io/blog/2022/02/breaking-into-industry-ml-ai-research-without-a-phd/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/blog/2022/02/breaking-into-industry-ml-ai-research-without-a-phd/</guid>
      <description>I am currently an Applied Scientist who is doing full-time machine learning (ML) research at Amazon without a PhD. I get to work on intellectually difficult problems with strong potential for greenfield innovation, work with really bright and motivated people, and earn high industry pay¹ while doing what I love. Unfortunately, while a lot of people are interested in entering machine learning, there isn’t a lot of guidance online for those trying to transition into ML from software engineering.</description>
    </item>
    
    <item>
      <title>Paper Summary for ShotCoL: Self-Supervised Video Representation Learning for Scene Boundary Detection in Movies and TV Episodes</title>
      <link>https://davidfan.io/blog/2021/06/paper-summary-for-shotcol-self-supervised-video-representation-learning-for-scene-boundary-detection-in-movies-and-tv-episodes/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/blog/2021/06/paper-summary-for-shotcol-self-supervised-video-representation-learning-for-scene-boundary-detection-in-movies-and-tv-episodes/</guid>
      <description>15 minute read.
Disclaimer: this paper summary exclusively represents my own views and DOES NOT represent the views of my employer nor my institution. This post should not in any way be treated as an official reference.
Roughly a year ago, I started doing research in self-supervised video representation learning with a focus on understanding long-form content. That work culminated in a second-author CVPR 2021 paper, which is the focus of this post.</description>
    </item>
    
    <item>
      <title>Reflections on 2010–2019</title>
      <link>https://davidfan.io/blog/2020/03/reflections-on-20102019/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/blog/2020/03/reflections-on-20102019/</guid>
      <description>Time flies! In 2010, I was in 7th grade and just beginning to mature. In 2015, I graduated from high school in NJ and entered college. In mid-2019, I graduated from college and moved from NJ to the West Coast for my first full-time job. To commemorate the ups-and-downs of the past decade, I decided to reflect on my experiences and what I learned from them. Those takeaways are condensed into four themes, in no particular order.</description>
    </item>
    
    <item>
      <title>The Story of Princeton University Science Olympiad</title>
      <link>https://davidfan.io/blog/2018/12/the-story-of-princeton-university-science-olympiad/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/blog/2018/12/the-story-of-princeton-university-science-olympiad/</guid>
      <description>Science Olympiad is a team-based STEM competition that approximately 8,000 middle school and high school teams compete in nationwide. Science Olympiad was a major part of my life from 7th to 12th grade, and an experience that I am very grateful to have had. In fall 2016 (my sophomore year), I cofounded the Princeton University Science Olympiad invitational tournament with Edison Lee. Co-founding this tournament and scaling it up to become one of Princeton’s largest student-run organizations, has been among the most difficult yet rewarding endeavors I have undertaken.</description>
    </item>
    
    <item>
      <title>Behind the Scenes: Challenges of Organizing HackPrinceton</title>
      <link>https://davidfan.io/blog/2018/11/behind-the-scenes-challenges-of-organizing-hackprinceton/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/blog/2018/11/behind-the-scenes-challenges-of-organizing-hackprinceton/</guid>
      <description>If you’ve ever attended a hackathon, you know how fun working on projects and learning in a fast-paced environment can be. There’s tons of technical workshops, speakers, mentors, great people, free food, energy drinks, hardware, and fun events. Maybe a bit of sleep too :)
A lot of work goes behind organizing a large hackathon like HackPrinceton, but not all of the work is “techy”. We grapple with many interesting logistical, communication, and management challenges, and I hope to give a glimpse of what some of those entail.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://davidfan.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/about/</guid>
      <description>Short Bio I graduated Magna Cum Laude from Princeton University in 2019 with a B.S.E in computer science. I am passionate about advancing the state-of-art in computer vision and deep learning research, as well as reducing the computational and domain knowledge barriers that prevent large-scale production use of machine learning. I am currently an Applied Scientist at Amazon, and was formerly a software engineer in AWS AI.
My current research interests are in video understanding, with a particular emphasis on self-supervised video representation learning from multiple modalities.</description>
    </item>
    
    <item>
      <title>Contact Me</title>
      <link>https://davidfan.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/contact/</guid>
      <description>Feel free to shoot me a message at anytime!
Email: dfan (at) davidfan.io
GitHub: github.com/dfan
LinkedIn: linkedin.com/in/davidfan97</description>
    </item>
    
    <item>
      <title>Experience</title>
      <link>https://davidfan.io/experience/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/experience/</guid>
      <description>Industry Amazon | Seattle, WA
Applied Scientist, May 2021 - present
Research Engineer, July 2020 - May 2021
 Developed self-supervised method for scene boundary detection that improves state-of-the-art by 13% even compared to fully-supervised methods, while reducing data labeling requirements by 75% and improving inference time by 84%.  Second-author paper accepted to CVPR 2021. Authored blog post on Amazon Research website.  Developed novel self-supervised video representation learning method that improves state-of-the-art in video action recognition.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://davidfan.io/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/projects/</guid>
      <description>Shot Contrastive Self-Supervised Learning for Scene Boundary Detection Scenes are critical to long-form video understanding as they delineate semantic progression. Localization of scenes is an important problem that is foundational to higher-level tasks in video understanding. Movies are particularly interesting as they are longer, more semantically complicated, and more visually challenging compared to most video datasets which contain clean short videos.
We present a novel pretext task that encourages the model to project embeddings from nearest neighboring shots to be closer in the embedding space than randomly sampled negative shots.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://davidfan.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://davidfan.io/publications/</guid>
      <description>Peer-Reviewed  Motion-Guided Masking for Spatiotemporal Representation Learning David Fan*, Jue Wang, Shuai Liao, Yi Zhu, Vimal Bhat, Hector Santos-Villalobos, Rohith MV, Xinyu Li.
ICCV 2023.
[Paper], [Blog Post Coming Up]
    Nearest-Neighbor Inter-Intra Contrastive Learning from Unlabeled Videos David Fan*, Deyu Yang, Xinyu Li, Vimal Bhat, Rohith MV.
ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models.
Paper, [Blog Post Coming Up]
    Shot Contrastive Self-Supervised Learning for Scene Boundary Detection Shixing Chen, Xiaohan Nie*, David Fan*, Dongqing Zhang, Vimal Bhat, Raffay Hamid.</description>
    </item>
    
  </channel>
</rss>